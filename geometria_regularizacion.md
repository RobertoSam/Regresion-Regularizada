# ğŸ§  GeometrÃ­a de la RegularizaciÃ³n

Las tÃ©cnicas de regresiÃ³n regularizada imponen restricciones geomÃ©tricas sobre los coeficientes del modelo. Estas restricciones se traducen en **regiones factibles** que influyen en la forma en que se encuentran las soluciones Ã³ptimas.

---

## ğŸ¨ ComparaciÃ³n geomÃ©trica

![GeometrÃ­a de Ridge, Lasso y Elastic Net](graficos_regularizacion/A_2D_digital_illustration_features_three_geometric.png)

Este grÃ¡fico muestra las regiones de penalizaciÃ³n para cada mÃ©todo:

- ğŸ”µ **Ridge**: penaliza con la norma L2 â†’ regiÃ³n **circular**  
  Favorece coeficientes pequeÃ±os pero no exactamente cero.  
  â• Bueno para **multicolinealidad**.

- â—¼ï¸ **Lasso**: penaliza con la norma L1 â†’ regiÃ³n **romboidal**  
  Tiende a empujar coeficientes exactamente a cero.  
  â• Ãštil para **selecciÃ³n de variables**.

- ğŸ”· **Elastic Net**: mezcla L1 + L2 â†’ regiÃ³n **intermedia**  
  Combina esparsidad con estabilidad.  
  â• Eficiente cuando hay **muchas variables correlacionadas**.

---

## ğŸ¯ Â¿Por quÃ© importa la geometrÃ­a?

El punto Ã³ptimo del modelo (mÃ­nimo del error cuadrÃ¡tico) se ve modificado por estas regiones:

- En **Ridge**, el mÃ­nimo se proyecta dentro del cÃ­rculo â†’ coeficientes pequeÃ±os.
- En **Lasso**, el mÃ­nimo puede "chocar" con los vÃ©rtices del rombo â†’ coeficientes cero.
- En **Elastic Net**, la soluciÃ³n transita entre ambas geometrÃ­as.

Estas formas geomÃ©tricas explican visualmente **cÃ³mo y por quÃ©** cada tÃ©cnica actÃºa diferente.

---

## ğŸ“š Referencias recomendadas

- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning*.
- James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). *An Introduction to Statistical Learning*.
- Zou, H., & Hastie, T. (2005). Regularization and variable selection via the elastic net.

---
