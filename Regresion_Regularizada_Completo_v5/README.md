# üìä Regresiones Regularizadas: Ridge, Lasso y Elastic Net

Este repositorio contiene una unidad completa sobre regresi√≥n regularizada en modelos lineales, orientada a estudiantes de maestr√≠a y profesionales en ciencia de datos y modelaci√≥n matem√°tica.

---

## üìÅ Contenido del repositorio

| Archivo | Descripci√≥n |
|--------|-------------|
| `regresion_regularizada_completa.ipynb` | Notebook integral con teor√≠a, aplicaci√≥n y comparaci√≥n de Ridge, Lasso y Elastic Net |
| `ridge_regression.ipynb` | Teor√≠a, visualizaci√≥n e implementaci√≥n completa de **Regresi√≥n Ridge** |
| `lasso_regression.ipynb` | Teor√≠a e implementaci√≥n de **Regresi√≥n Lasso**, con enfoque en selecci√≥n de variables |
| `elasticnet_regression.ipynb` | An√°lisis de **Elastic Net**, mostrando c√≥mo combina Ridge y Lasso |
| `comparacion_modelos_regularizados.ipynb` | Comparaci√≥n pr√°ctica y gr√°fica entre los tres modelos |
| `graficos_regularizacion/` | Im√°genes explicativas sobre las regiones geom√©tricas de cada modelo |

---

## üéØ Objetivos de aprendizaje

- Comprender las limitaciones de la regresi√≥n OLS y c√≥mo la regularizaci√≥n las mitiga.
- Conocer el fundamento te√≥rico y geom√©trico de Ridge, Lasso y Elastic Net.
- Aplicar cada t√©cnica en un ejemplo real, analizar sus coeficientes y evaluar su rendimiento.
- Validar los supuestos del modelo usando an√°lisis de residuos.
- Comparar los tres m√©todos y justificar su elecci√≥n en problemas reales.

---

## üß† Geometr√≠a de la regularizaci√≥n

![Geometr√≠a de Ridge, Lasso y Elastic Net](graficos_regularizacion/A_2D_digital_illustration_displays_geometric_repre.png)

> Este gr√°fico representa c√≥mo la elecci√≥n de la penalizaci√≥n impone distintas **regiones geom√©tricas de soluci√≥n**:
> - **Ridge**: regi√≥n circular ‚Üí todos los coeficientes peque√±os
> - **Lasso**: regi√≥n romboidal ‚Üí muchos coeficientes exactamente cero
> - **Elastic Net**: regi√≥n curva intermedia ‚Üí mezcla entre Ridge y Lasso

---

## ‚öôÔ∏è Tecnolog√≠as utilizadas

- Python 3.11
- Scikit-learn
- Numpy, Matplotlib, Seaborn
- Statsmodels, Scipy

---

## üöÄ Ejecutar en l√≠nea

- [Notebook completo en Colab](https://colab.research.google.com/github/RobertoSam/Regresion-Regularizada/blob/main/regresion_regularizada_completa.ipynb)
- [Abrir Ridge en Google Colab](https://colab.research.google.com/github/RobertoSam/Regresion-Regularizada/blob/main/ridge_regression.ipynb)
- [Abrir Lasso en Colab](https://colab.research.google.com/github/RobertoSam/Regresion-Regularizada/blob/main/lasso_regression.ipynb)
- [Abrir Elastic Net en Colab](https://colab.research.google.com/github/RobertoSam/Regresion-Regularizada/blob/main/elasticnet_regression.ipynb)
- [Comparaci√≥n en Colab](https://colab.research.google.com/github/RobertoSam/Regresion-Regularizada/blob/main/comparacion_modelos_regularizados.ipynb)

---

## üõ† Instalaci√≥n local r√°pida

1. Clona este repositorio:
```bash
git clone https://github.com/RobertoSam/Regresion-Regularizada.git
cd Regresion-Regularizada
```

2. Crea un entorno virtual (opcional pero recomendado):
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. Instala las dependencias:
```bash
pip install -r requirements.txt
```

4. Abre los notebooks:
```bash
jupyter notebook
```

---

## üìö Aplicaciones actuales

Las t√©cnicas de regresi√≥n regularizada se usan ampliamente en:

- Gen√≥mica y biolog√≠a computacional
- Marketing predictivo
- Selecci√≥n de variables en modelos con alta dimensionalidad
- Modelos de series temporales con m√∫ltiples covariables

---

## üë®‚Äçüè´ Autor

Material desarrollado por **Roberto Sam** para la Maestr√≠a en Modelizaci√≥n Matem√°tica y Computacional ‚Äì Universidad Nacional de Ingenier√≠a (UNI), Per√∫.  
Asistencia t√©cnica y did√°ctica desarrollada con ayuda de un asistente acad√©mico especializado en matem√°ticas aplicadas y ciencia de datos.


---

## üöÄ Ejecutar en Google Colab

Puedes ejecutar el notebook directamente en [Google Colab](https://colab.research.google.com/) sin instalar nada localmente.

### üìÇ Desde Google Drive

1. Guarda `regresion_regularizada_completa.ipynb` en tu Google Drive.
2. Abre [https://colab.research.google.com](https://colab.research.google.com)
3. Selecciona el archivo desde la pesta√±a **Google Drive**
4. Ejecuta normalmente por celdas.

---

### üîó Desde GitHub

Si tienes el repositorio en GitHub (`RobertoSam/Regresion-Regularizada`), puedes abrirlo as√≠:

```bash
https://colab.research.google.com/github/RobertoSam/Regresion-Regularizada/blob/main/Regresion_Regularizada_Completo/regresion_regularizada_completa.ipynb
```

### ‚ñ∂Ô∏è Enlaces r√°pidos por t√©cnica (si el notebook tiene t√≠tulos apropiados):

| T√©cnica         | Fragmento Colab (#scrollTo=...) |
|----------------|----------------------------------|
| **Ridge**       | `#scrollTo=ridge`               |
| **Lasso**       | `#scrollTo=lasso`               |
| **Elastic Net** | `#scrollTo=elasticnet`          |

> Puedes combinar el enlace base con estos fragmentos para llegar directamente a cada secci√≥n.
