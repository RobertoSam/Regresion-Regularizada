{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb24116",
   "metadata": {},
   "source": [
    "## 📚 Origen de los nombres: Ridge, Lasso y Elastic Net\n",
    "\n",
    "Además de su base matemática, los nombres de estos modelos tienen un origen interesante:\n",
    "\n",
    "### 🟦 Ridge Regression\n",
    "- **“Ridge”** significa *cresta*.\n",
    "- Hace alusión a la forma de la penalización cuadrática \\( \\|\\beta\\|_2^2 \\), que crea una barrera o “colina” alrededor del origen.\n",
    "- El nombre fue propuesto por **Hoerl y Kennard (1970)** para reflejar cómo la penalización estabiliza la superficie de solución.\n",
    "\n",
    "---\n",
    "\n",
    "### ✂️ Lasso\n",
    "- Acrónimo de: **Least Absolute Shrinkage and Selection Operator**.\n",
    "- Propuesto por **Robert Tibshirani (1996)**.\n",
    "- “Lasso” también significa *lazo* en inglés, y sugiere que el modelo “ata” algunos coeficientes a cero.\n",
    "- Metáfora visual: el lazo tira de los coeficientes hacia los ejes.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔗 Elastic Net\n",
    "- Introducido por **Zou y Hastie (2005)**.\n",
    "- El nombre simboliza una **“red elástica”** que mezcla L1 (Lasso) y L2 (Ridge).\n",
    "- Imita una malla flexible que combina contracción y selección de variables, ideal cuando hay muchas variables correlacionadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d819798c",
   "metadata": {},
   "source": [
    "# 🧾 Capítulo extra: Origen de los nombres Ridge, Lasso y Elastic Net\n",
    "\n",
    "Comprender el origen de estos nombres ayuda a conectar la geometría, la intuición estadística y la evolución histórica de cada método.\n",
    "\n",
    "---\n",
    "\n",
    "## 🟦 Ridge Regression\n",
    "\n",
    "- **“Ridge”** significa *cresta*.\n",
    "- Fue nombrado por Hoerl y Kennard (1970) al observar que la penalización cuadrática \\( \\|\\beta\\|_2^2 \\) actúa como una cresta que suaviza las soluciones en presencia de multicolinealidad.\n",
    "- Su función objetivo es:\n",
    "  \\[\n",
    "  \\min_{\\beta} \\left\\{ \\| y - X\\beta \\|_2^2 + \\lambda \\| \\beta \\|_2^2 \\right\\}\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "## ✂️ Lasso\n",
    "\n",
    "- Acrónimo de **Least Absolute Shrinkage and Selection Operator**\n",
    "- Propuesto por Robert Tibshirani (1996)\n",
    "- Combina dos ideas clave:\n",
    "  - **Contracción** de coeficientes (como Ridge)\n",
    "  - **Selección automática de variables** (gracias a la penalización \\( L_1 \\))\n",
    "- El nombre *“Lasso”* también sugiere un **lazo que atrapa** y anula coeficientes.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 Elastic Net\n",
    "\n",
    "- Introducido por Zou y Hastie (2005)\n",
    "- Combina Ridge y Lasso:\n",
    "  \\[\n",
    "  \\min_{\\beta} \\left\\{ \\| y - X\\beta \\|_2^2 + \\lambda \\left( \\alpha \\| \\beta \\|_1 + (1 - \\alpha) \\| \\beta \\|_2^2 \\right) \\right\\}\n",
    "  \\]\n",
    "- El nombre *Elastic Net* evoca una **red elástica**:\n",
    "  - Se adapta a datos complejos\n",
    "  - Combina estabilidad (Ridge) y selección (Lasso)\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Resumen\n",
    "\n",
    "| Método | Nombre sugiere… | Intención |\n",
    "|--------|------------------|-----------|\n",
    "| Ridge  | Estabilidad con una “cresta” de penalización | Evitar coeficientes grandes |\n",
    "| Lasso  | Un lazo que “ata” coeficientes a cero | Selección de variables |\n",
    "| Elastic Net | Una red flexible que combina lo mejor de ambos | Adaptabilidad y robustez |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
